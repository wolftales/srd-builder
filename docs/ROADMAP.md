# ğŸ§­ SRD-Builder â€” Roadmap (PDF âœ JSON)

The builder ingests **source PDFs** under `rulesets/<ruleset>/raw/*.pdf`
and produces **deterministic JSON datasets** in multiple stages.

```
PDF  â”€â–º  text extraction  â”€â–º  raw JSON (verbatim blocks)
        rulesets/<ruleset>/raw/extracted/monsters_raw.json
                       â”‚
                       â–¼
            parse_monsters.py (field mapping)
                       â–¼
            postprocess.py (clean & normalize)
                       â–¼
            dist/<ruleset>/data/monsters.json  â† clean, deterministic output
```
---

## **v0.1.0 â€” Foundation** âœ…

**Goal:** get a working build command and CI flow.

**Delivers**

* `build.py` runs end-to-end and creates `dist/<ruleset>/build_report.json`.
* `validate.py` exists (even if stubbed).
* CI passes: ruff, black, pytest, mypy.
* Directory layout fixed:

  ```
  src/srd_builder/
  rulesets/<ruleset>/raw/
  dist/<ruleset>/
  ```

*Status:* **COMPLETE** - Infrastructure and tooling in place.

---

## **v0.2.0 â€” End-to-End Pipeline** ğŸš§

**Goal:** prove the full build pipeline works with **fixture data** (not PDF extraction yet).

**What Works**

```
rulesets/srd_5_1/raw/monsters.json  (fixture from tests/)
   â”‚
   â”œâ”€â–º parse_monsters.py      â†’ field mapping
   â”œâ”€â–º postprocess.py         â†’ normalization & cleanup
   â””â”€â–º indexer.py             â†’ build lookups
   â”‚
   â–¼
dist/srd_5_1/data/monsters.json     # normalized output
dist/srd_5_1/data/index.json        # lookup maps
   â”‚
   â–¼
validate.py  â† schema validation passes
```

**Outputs**

```
dist/<ruleset>/build_report.json
dist/<ruleset>/data/monsters.json
dist/<ruleset>/data/index.json
```

**Commands**

```bash
python -m srd_builder.build --ruleset srd_5_1 --out dist
python -m srd_builder.validate --ruleset srd_5_1
```

*Purpose:* Validate that parse â†’ postprocess â†’ index â†’ validate chain works correctly before tackling PDF extraction.

---

## **v0.3.0 â€” PDF Extraction**

**Goal:** extract *monsters* text blocks directly from the PDF
and serialize them as **raw, unprocessed JSON**.

**New Module**

```python
src/srd_builder/extract_monsters.py
```

**Outputs**

```
rulesets/<ruleset>/raw/extracted/monsters_raw.json
```

**Contents of `monsters_raw.json`:**

* One entry per monster block from the PDF.
* Fields mostly unparsed â€” strings for AC, HP, actions, etc.
* Page references and offsets retained.

**Integration**

* `build.py` calls `extract_monsters_from_pdf(pdf_path)` instead of loading pre-existing JSON
* Optional: compute and record PDF SHA-256 in `build_report.json`

*This is the "read from source PDF" milestone.*

---

## **v0.4.0 â€” Extraction Quality Pass (monsters)**

**Goal:** improve PDF segmentation fidelity.

**Planned**

* Better block detection (headers, "Armor Class", "Hit Points", "Actions", etc.).
* Robust dice/bonus parsing; multi-line traits/actions join rules.
* Handle edge cases (legendary actions, lair actions, regional effects).
* Page cross-check using page index metadata.

---

## **v0.5.0 â€” Additional Entities**

**Goal:** repeat the extraction+normalize flow for:

* Equipment
* Lineages
* (Later) Classes, Spells, Features

Each follows the same three-stage pattern:
`extract_*` â†’ `parse_*` â†’ `postprocess` â†’ `indexer`.

---

## **v0.6.0 â€” Unified Build & Validation**

**Goal:** single `build_all()` to process all entities and a top-level `validate_all()` for all schemas and PDFs.

---

### Principles

* **Source of truth:** the PDF, not pre-existing JSON.
* **Fixtures:** used only for unit/golden tests.
* **Determinism:** identical inputs yield identical outputs.
* **Layered:** extract â†’ parse â†’ postprocess â†’ index â†’ validate.
* **No timestamps in dataset files.**

---
